<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>  PROJECTS  </title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <section>
        <h2> Project 1: Neural Network for Vehicle Dynamics Modeling</h2>
        <p>This project is focused on developing a neural network model to accurately predict the dynamics of a vehicle based on various sensor inputs. By utilizing deep learning techniques, this model aims to improve the understanding of how vehicles behave under different conditions, contributing to advancements in autonomous driving, vehicle control, and optimization systems.</p>

        <h2>Features</h2>
        <ul>
            <li>Utilizes real-world vehicle dynamics data.</li>
            <li>Trained using Python and Keras with TensorFlow backend.</li>
            <li>Evaluates vehicle stability, handling, and control behavior.</li>
            <li>Includes performance metrics and visualizations.</li>
            <li>Implemented optimization techniques for better model accuracy.</li>
        </ul>

        <h2>Technologies Used</h2>
        <ul>
            <li>Python</li>
            <li>Keras & TensorFlow</li>
            <li>NumPy & Pandas</li>
            <li>Matplotlib & Seaborn</li>
            <li>GitHub Actions</li>
        </ul>

        <h2>Project Status</h2>
        <p>The model has been trained on vehicle sensor data and is being fine-tuned to ensure high accuracy in predicting vehicle behavior in different scenarios. Future improvements include enhancing the model with more data and incorporating additional vehicle states for better control predictions.</p>

        <h2>Links</h2>
        <p>
            <a href="https://github.com/TUMFTM/NeuralNetwork_for_VehicleDynamicsModeling">GitHub Repository</a>
            <br>
            <a href="#">Live Demo (optional)</a>
        </p>
    </section>

    <!-- New Section for the Chatbot Project -->
    <section>
        <h2>Project 2: Chat with Gemini Model Project ðŸŒ± </h2>
        <p>This project showcases the use of Google Gemini and Streamlit to create a simple chatbot interface. The chatbot interacts with users to answer questions using Google's Gemini-1.5 model via the Generative AI API.</p>

        <h3>Features</h3>
        <ul>
            <li>Streamlit interface for question and answer functionality</li>
            <li>Utilizes Google Gemini for natural language processing</li>
            <li>Real-time chatbot interactions</li>
        </ul>

        <h3>Technologies Used</h3>
        <ul>
            <li>Streamlit</li>
            <li>Google Generative AI API</li>
            <li>Python</li>
        </ul>
        
        <!-- Adding Image for Project 2 -->
        <img src="images/chatbot_project_image.png" alt="Chatbot Project Image " width="500">
        
        <h3>Links</h3>
        <p>
            <a href="https://github.com/your-username/chatbot_project">GitHub Repository for Chatbot</a>
            <br>
            <a href="#">Live Demo (optional)</a>
        </p>
    </section>

<!-- New Section for Project 3 -->
    <section>
        <h2>Project 3: QA Bot with LangChain, LLM, and IBM Watson AI</h2>
        <p>This project involves creating a question-answering bot that uses LangChain, IBM Watson AI, and a large language model (LLM) to answer questions based on content from loaded PDF documents. The bot integrates various components such as document loaders, text splitters, embedding models, vector databases, and retrievers to deliver accurate responses. The user interacts with the bot through a Gradio front-end interface, making it easy to use.</p>

        <h3>Features</h3>
        <ul>
            <li>Loads and processes large PDF documents for content retrieval</li>
            <li>Leverages IBM Watson AI and LangChain for NLP</li>
            <li>Integrates Gradio for a user-friendly front-end interface</li>
            <li>Efficient retrieval of relevant information from vector databases</li>
        </ul>

        <h3>Technologies Used</h3>
        <ul>
            <li>LangChain</li>
            <li>IBM Watson AI</li>
            <li>Large Language Models (LLM)</li>
            <li>Gradio Interface</li>
            <li>Python</li>
        </ul>

        <!-- Adding Image for Project 3 -->
        <img src="images/gradio_watson_ai_llm_chatbot.png" alt="Chatbot Project Image " width="500">
        
        <h3>Links</h3>
        <p>
            <a href="https://github.com/your-username/qa_bot_project">GitHub Repository for QA Bot Project</a>
            <br>
            <a href="#">Live Demo (optional)</a>
        </p>
    </section>
    
<!-- New Section for Project 4 -->
    <section>
        <h2>Project 4: MLOps with Hugging Face & GitHub Actions</h2>
        <p>This project demonstrates the integration of MLOps principles by automating model deployment workflows using Hugging Face Spaces and GitHub Actions. The project automates syncing the local machine learning project to Hugging Face Spaces whenever new changes are pushed to the repository, streamlining the deployment process and ensuring continuous integration and delivery (CI/CD).</p>

        <!-- Adding Image for Project 4a -->
        <img src="images/Mlops_HFS_gradio_flow.png" alt="Project Image 4a " width="500">
        
        <h3>Features</h3>
        <ul>
            <li>GitHub Actions for CI/CD pipeline automation</li>
            <li>Automated model deployment to Hugging Face Spaces</li>
            <li>Easy synchronization of local changes with Hugging Face for continuous updates</li>
            <li>Supports both manual workflow dispatch and push-based triggers</li>
        </ul>

        <h3>Technologies Used</h3>
        <ul>
            <li>GitHub Actions</li>
            <li>Hugging Face Spaces</li>
            <li>Python</li>
        </ul>

        <!-- Adding Image for Project 4b -->
        <img src="images/Mlops_HFS_gradio_summarization.png" alt="Project Image 4b " width="500">
        
        <h3>Links</h3>
        <p>
            <a href="https://github.com/parasmech/Mlops_hugging_face_github_actions">GitHub Repository for MLOps Project</a>
            <br>
            <a href="https://huggingface.co/spaces/parasmech/Mlops">Live Demo (optional)</a>
        </p>
    </section>

        <!-- Updated Section for Project 5 -->
    <section>
        <h2>Project 5: Dialog Summarization using Generative AI on AWS SageMaker</h2>
        <p>This project focuses on summarizing dialogues using a Generative AI model deployed on AWS SageMaker. It demonstrates the exploration of how different inputs and prompt engineering techniques affect the modelâ€™s summarization capabilities. The project is structured around multiple steps to improve the summarization through zero-shot, one-shot, and few-shot inference techniques, using generative models like FLAN-T5.</p>

        <h3>Project Workflow</h3>
        <ol>
            <li><strong>Set up Kernel and Required Dependencies:</strong> The environment was set up on AWS SageMaker, and dependencies were installed for model inference and testing.</li>
            <li><strong>Summarize Dialogue without Prompt Engineering:</strong> The model generates basic summaries without specific instructions, demonstrating the default capabilities of the LLM in summarizing conversations.</li>
            <li><strong>Summarize Dialogue with an Instruction Prompt:</strong> This step adds an instruction prompt to guide the model towards producing more relevant summaries. 
                <ul>
                    <li><strong>Zero Shot Inference with an Instruction Prompt:</strong> No examples are provided, and the model directly uses the prompt to generate a summary.</li>
                    <li><strong>Zero Shot Inference with the Prompt Template from FLAN-T5:</strong> A specialized prompt template designed for dialogue summarization, leveraging the capabilities of FLAN-T5.</li>
                </ul>
            </li>
            <li><strong>Summarize Dialogue with One Shot and Few Shot Inference:</strong> In this phase, example dialogues are provided to fine-tune the model's output further.
                <ul>
                    <li><strong>One Shot Inference:</strong> A single example is given to the model before performing inference, leading to improved contextual summarization.</li>
                    <li><strong>Few Shot Inference:</strong> Several examples are provided, further enhancing the model's ability to generate accurate dialogue summaries.</li>
                </ul>
            </li>
            <li><strong>Generative Configuration Parameters for Inference:</strong> Various configuration parameters like temperature, maximum tokens, and top-p were experimented with to fine-tune the output and improve model behavior during inference.</li>
        </ol>

        <h3>Features</h3>
        <ul>
            <li>Dialog summarization using generative AI deployed on AWS SageMaker</li>
            <li>Experimentation with zero-shot, one-shot, and few-shot inferences</li>
            <li>Prompt engineering to improve summarization accuracy</li>
            <li>Configuration of generative parameters to refine model output</li>
        </ul>

        <h3>Technologies Used</h3>
        <ul>
            <li>AWS SageMaker</li>
            <li>Generative AI models (FLAN-T5)</li>
            <li>Python</li>
        </ul>

        <h3>Links</h3>
        <p>
            <a href="https://github.com/parasmech/GenAI_with_LLM_AWS_SageMaker/blob/main/Summarize_Dialogue.ipynb">GitHub Repository</a> 
        </p>
    </section>

        <!-- New Section for Project 6 -->
    <section>
        <h2>Project 6: Fine-Tuning a Generative AI Model for Dialogue Summarization with PEFT</h2>
        <p>This project involves fine-tuning an existing large language model (LLM) from Hugging Face for enhanced dialogue summarization. Using the FLAN-T5 model, which provides a high-quality instruction-tuned framework, this project focuses on improving dialogue summarization performance through both full fine-tuning and Parameter Efficient Fine-Tuning (PEFT). The project aims to enhance the modelâ€™s ability to summarize conversations while evaluating the trade-offs between fine-tuning strategies using the ROUGE metric.</p>

        <h3>Features</h3>
        <ul>
            <li>Full fine-tuning of the FLAN-T5 model for enhanced dialogue summarization</li>
            <li>Utilizes Parameter Efficient Fine-Tuning (PEFT) techniques to minimize resource usage</li>
            <li>Evaluation of the model using human assessments and ROUGE metrics</li>
        </ul>

        <h3>Technologies Used</h3>
        <ul>
            <li>Hugging Face LLM (FLAN-T5)</li>
            <li>Parameter Efficient Fine-Tuning (PEFT/LoRA)</li>
            <li>AWS SageMaker</li>
            <li>Python</li>
            <li>ROUGE Metrics</li>
        </ul>

        <h3>Links</h3>
        <p>
            <a href="https://github.com/parasmech/GenAI_with_LLM_AWS_SageMaker/blob/main/Fine_tune_Generative_AI_model_PEFT.ipynb">GitHub Repository for Fine-Tuning Generative AI Model</a>  
        </p>
    </section>

    <section>
    <h2>Project 7: Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries </h2>
    <p>This project explores how to fine-tune a FLAN-T5 model using Proximal Policy Optimization (PPO) and Parameter-Efficient Fine-Tuning (PEFT) techniques to generate less toxic content. Leveraging Meta AI's hate speech reward model, the fine-tuning process adjusts the modelâ€™s output to minimize harmful or toxic content. The reward model is a binary classifier that categorizes the generated content as either "hate" or "not hate," and the goal is to reduce the toxicity of the generated summaries.</p>
    
    <h3>Features</h3>
    <ul>
        <li>Fine-tuning of a pre-trained FLAN-T5 model using reinforcement learning</li>
        <li>Use of Meta AI's hate speech reward model to guide the detoxification process</li>
        <li>Evaluates model performance using both qualitative and quantitative methods</li>
        <li>Application of Proximal Policy Optimization (PPO) for efficient fine-tuning</li>
        <li>Includes Parameter-Efficient Fine-Tuning (PEFT) for less resource-intensive training</li>
    </ul>

    <h3>Technologies Used</h3>
    <ul>
        <li>AWS SageMaker for model training</li>
        <li>FLAN-T5 model</li>
        <li>Proximal Policy Optimization (PPO)</li>
        <li>Meta AI's Hate Speech Reward Model</li>
        <li>PEFT techniques</li>
    </ul>

    <h3>Links</h3>
    <p>
        <a href="https://github.com/parasmech/GenAI_with_LLM_AWS_SageMaker/blob/main/Fine_tune_model_to_detoxify_summaries_RLHF.ipynb">GitHub Repository for Fine-Tuning Project</a>
    </p>
    </section>

    <section>
    <h2>Project 8: Automated Recipe-based Shopping List and Image Generation</h2>
    <p>This project utilizes OpenAI's GPT-3.5 and DALL-E models to create a seamless experience for users to generate shopping lists from recipes and visualize them. Users input a recipe, and the system generates a shopping list based on the ingredients needed, as well as provides goods that complement the recipe. Additionally, DALL-E generates a relevant image of one of the items in the shopping list to enhance the user experience.</p>
    
    <h3>Features</h3>
    <ul>
        <li>Automated generation of shopping lists based on recipe inputs</li>
        <li>Integration with GPT-3.5 for natural language processing and list generation</li>
        <li>Image generation using DALL-E for visual representation of recipe items</li>
        <li>Efficient extraction of ingredients using Python's regex capabilities</li>
        <li>Customization of prompt settings for varied output</li>
    </ul>

    <h3>Technologies Used</h3>
    <ul>
        <li>OpenAI GPT-3.5 for text generation</li>
        <li>DALL-E for image generation</li>
        <li>Python's regex module for text processing</li>
    </ul>
    <!-- Adding Image for Project 8 -->
        <img src="images/shopping_list_DallE.png" alt="Chatbot Project Image " width="500">
        
</section>

<section>
    <h2>Project 9: Retrieval Augmented Generation with Local LLMs </h2>
    <p>This project demonstrates the implementation of the Retrieval Augmented Generation (RAG) pattern using a local LLM, FastAPI, and the Qdrant vector database. The goal is to provide fast and accurate responses by leveraging your own data. The project is based on the RAG pattern, enhanced with local inferencing and Qdrant for vector storage and retrieval.</p>

    <h3>Features</h3>
    <ul>
        <li>Retrieval Augmented Generation (RAG) pattern implementation using local CSV data</li>
        <li>Integration of FastAPI for fast local inference with a local LLM</li>
        <li>Connection to a vector database (Qdrant) to store and retrieve document embeddings</li>
        <li>Use of Sentence Transformers for embedding creation</li>
        <li>Local LLM inferencing with Ollama to enhance response times</li>
    </ul>

    <h3>Technologies Used</h3>
    <ul>
        <li>FastAPI for API development</li>
        <li>Qdrant for vector database management</li>
        <li>Sentence Transformers for embedding generation</li>
        <li>Ollama for running local LLM inferencing</li>
        <li>Python for API and LLM integration</li>
    </ul>

    <!-- Adding Image for Project 9 -->
    <img src="RAG_chat_with_local_llms_ollama_qdrant_code.png" alt="RAG Project Code Image" width="500">
    <img src="RAG_chat_with_local_llms_ollama_qdrant.png" alt="RAG Project Image" width="500">


</section>

<section>
    <h2>Project 10: Ollama - Run Large Language Models Locally </h2>
    <p>This project demonstrates the use of <strong>Ollama</strong> to run large language models such as Llama 2, Phi, and Code Llama locally on your system. The project exposes an OpenAI-compatible API through Ollama, allowing you to connect to these models using Python. For deployment, <strong>Gradio</strong> is used to create an interactive interface, enabling users to chat with local LLMs and explore various use cases.</p>
    
    <h3>Features</h3>
    <ul>
        <li>Run large language models like Llama 2, Phi, and Code Llama locally</li>
        <li>Connect to local LLMs using OpenAI's Python API</li>
        <li>Deploy an interactive chat interface using Gradio</li>
        <li>Explore various LLM functionalities in a local environment</li>
    </ul>

    <h3>Technologies Used</h3>
    <ul>
        <li>Ollama for running local LLM instances</li>
        <li>OpenAI's Python API for connecting to LLMs</li>
        <li>Gradio for deploying a user-friendly interface</li>
    </ul>
     <!-- Adding Image for Project 9 -->
    <img src="chat_with_local_llms_ollama_code.png" alt="RAG Project Code Image" width="500">
    <img src="chat_with_local_llms_ollama.png" alt="RAG Project Image" width="500">
   
</section>

    
    
</body>
</html>


